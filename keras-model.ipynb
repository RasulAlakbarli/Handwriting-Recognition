{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f64d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random as random\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932f06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ef2527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "test_X_visual = test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bffb7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(60000, 784) / 255\n",
    "test_X = test_X.reshape(10000, 784) / 255\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc55bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.max()+1,Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "    return one_hot_Y\n",
    "\n",
    "train_Y = one_hot(train_y).T\n",
    "test_Y = one_hot(test_y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ed296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train_X:  (60000, 784)\n",
      "Shape of Train_Y:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train_X: \", train_X.shape)\n",
    "print(\"Shape of Train_Y: \", train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf4b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape = (784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e7d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99fcdc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 6s - loss: 0.2502 - accuracy: 0.9252 - val_loss: 0.0896 - val_accuracy: 0.9731 - 6s/epoch - 14ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 6s - loss: 0.1006 - accuracy: 0.9690 - val_loss: 0.0561 - val_accuracy: 0.9823 - 6s/epoch - 13ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 6s - loss: 0.0712 - accuracy: 0.9774 - val_loss: 0.0352 - val_accuracy: 0.9892 - 6s/epoch - 13ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 6s - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0311 - val_accuracy: 0.9902 - 6s/epoch - 13ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 6s - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0210 - val_accuracy: 0.9934 - 6s/epoch - 13ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 6s - loss: 0.0409 - accuracy: 0.9871 - val_loss: 0.0134 - val_accuracy: 0.9963 - 6s/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 6s - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0133 - val_accuracy: 0.9959 - 6s/epoch - 13ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 6s - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0103 - val_accuracy: 0.9969 - 6s/epoch - 13ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 6s - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0125 - val_accuracy: 0.9960 - 6s/epoch - 14ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 6s - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0153 - val_accuracy: 0.9948 - 6s/epoch - 13ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 6s - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0089 - val_accuracy: 0.9973 - 6s/epoch - 14ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 6s - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0056 - val_accuracy: 0.9984 - 6s/epoch - 13ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 6s - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0084 - val_accuracy: 0.9971 - 6s/epoch - 14ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 6s - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0076 - val_accuracy: 0.9977 - 6s/epoch - 13ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 6s - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0053 - val_accuracy: 0.9981 - 6s/epoch - 13ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 6s - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0046 - val_accuracy: 0.9985 - 6s/epoch - 14ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 6s - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0051 - val_accuracy: 0.9984 - 6s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 6s - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0043 - val_accuracy: 0.9987 - 6s/epoch - 14ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 6s - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0044 - val_accuracy: 0.9987 - 6s/epoch - 13ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 6s - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0044 - val_accuracy: 0.9986 - 6s/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y,\n",
    "                   batch_size=128, epochs=20,\n",
    "                   verbose=2,\n",
    "                   validation_data=(train_X, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27f51ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /Desktop/Neural Network Projects/Handwriting Recognition/keras_mnist.h5 \n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/Desktop/Neural Network Projects/Handwriting Recognition/\"\n",
    "model_name = 'keras_mnist.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d71b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9826\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Model loss:  0.0800371915102005\n",
      "Model accuracy:  0.9825999736785889\n"
     ]
    }
   ],
   "source": [
    "mnist_model = load_model(\"/Desktop/Neural Network Projects/Handwriting Recognition/keras_mnist.h5\")\n",
    "\n",
    "loss_and_metrics = mnist_model.evaluate(test_X, test_Y)\n",
    "\n",
    "predicted_classes = mnist_model.predict(test_X)\n",
    "\n",
    "print(\"Model loss: \", loss_and_metrics[0])\n",
    "print(\"Model accuracy: \", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6f9421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value:  4\n",
      "Predicted Value:  4\n"
     ]
    }
   ],
   "source": [
    "random_number = random.randint(1, 9999)\n",
    "\n",
    "image = test_X_visual[random_number]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Actual Value: \", test_y[random_number])\n",
    "print(\"Predicted Value: \", np.argmax(predicted_classes[random_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb388354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
