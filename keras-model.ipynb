{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f64d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random as random\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "932f06ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef2527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "test_X_visual = test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bffb7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(60000, 784) / 255\n",
    "test_X = test_X.reshape(10000, 784) / 255\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc55bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(Y):\n",
    "    one_hot_Y = np.zeros((Y.max()+1,Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "    return one_hot_Y\n",
    "\n",
    "train_Y = one_hot(train_y).T\n",
    "test_Y = one_hot(test_y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1ed296e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train_X:  (60000, 784)\n",
      "Shape of Train_Y:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train_X: \", train_X.shape)\n",
    "print(\"Shape of Train_Y: \", train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf4b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape = (784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37e7d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99fcdc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 6s - loss: 0.2502 - accuracy: 0.9252 - val_loss: 0.0896 - val_accuracy: 0.9731 - 6s/epoch - 14ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 6s - loss: 0.1006 - accuracy: 0.9690 - val_loss: 0.0561 - val_accuracy: 0.9823 - 6s/epoch - 13ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 6s - loss: 0.0712 - accuracy: 0.9774 - val_loss: 0.0352 - val_accuracy: 0.9892 - 6s/epoch - 13ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 6s - loss: 0.0568 - accuracy: 0.9816 - val_loss: 0.0311 - val_accuracy: 0.9902 - 6s/epoch - 13ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 6s - loss: 0.0484 - accuracy: 0.9836 - val_loss: 0.0210 - val_accuracy: 0.9934 - 6s/epoch - 13ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 6s - loss: 0.0409 - accuracy: 0.9871 - val_loss: 0.0134 - val_accuracy: 0.9963 - 6s/epoch - 13ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 6s - loss: 0.0339 - accuracy: 0.9889 - val_loss: 0.0133 - val_accuracy: 0.9959 - 6s/epoch - 13ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 6s - loss: 0.0308 - accuracy: 0.9898 - val_loss: 0.0103 - val_accuracy: 0.9969 - 6s/epoch - 13ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 6s - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.0125 - val_accuracy: 0.9960 - 6s/epoch - 14ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 6s - loss: 0.0243 - accuracy: 0.9916 - val_loss: 0.0153 - val_accuracy: 0.9948 - 6s/epoch - 13ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 6s - loss: 0.0244 - accuracy: 0.9924 - val_loss: 0.0089 - val_accuracy: 0.9973 - 6s/epoch - 14ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 6s - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.0056 - val_accuracy: 0.9984 - 6s/epoch - 13ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 6s - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0084 - val_accuracy: 0.9971 - 6s/epoch - 14ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 6s - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0076 - val_accuracy: 0.9977 - 6s/epoch - 13ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 6s - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0053 - val_accuracy: 0.9981 - 6s/epoch - 13ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 6s - loss: 0.0190 - accuracy: 0.9938 - val_loss: 0.0046 - val_accuracy: 0.9985 - 6s/epoch - 14ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 6s - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.0051 - val_accuracy: 0.9984 - 6s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 6s - loss: 0.0184 - accuracy: 0.9945 - val_loss: 0.0043 - val_accuracy: 0.9987 - 6s/epoch - 14ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 6s - loss: 0.0140 - accuracy: 0.9949 - val_loss: 0.0044 - val_accuracy: 0.9987 - 6s/epoch - 13ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 6s - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.0044 - val_accuracy: 0.9986 - 6s/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y,\n",
    "                   batch_size=128, epochs=20,\n",
    "                   verbose=2,\n",
    "                   validation_data=(train_X, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27f51ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trained model at /Desktop/Neural Network Projects/Handwriting Recognition/keras_mnist.h5 \n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/Desktop/Neural Network Projects/Handwriting Recognition/\"\n",
    "model_name = 'keras_mnist.h5'\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d71b935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9826\n",
      "313/313 [==============================] - 1s 3ms/step\n",
      "Model loss:  0.0800371915102005\n",
      "Model accuracy:  0.9825999736785889\n"
     ]
    }
   ],
   "source": [
    "mnist_model = load_model(\"/Desktop/Neural Network Projects/Handwriting Recognition/keras_mnist.h5\")\n",
    "\n",
    "loss_and_metrics = mnist_model.evaluate(test_X, test_Y)\n",
    "\n",
    "predicted_classes = mnist_model.predict(test_X)\n",
    "\n",
    "print(\"Model loss: \", loss_and_metrics[0])\n",
    "print(\"Model accuracy: \", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6f9421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Value:  3\n",
      "Predicted Value:  3\n"
     ]
    }
   ],
   "source": [
    "random_number = random.randint(1, 9999)\n",
    "\n",
    "image = test_X_visual[random_number]\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print(\"Actual Value: \", test_y[random_number])\n",
    "print(\"Predicted Value: \", np.argmax(predicted_classes[random_number]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb388354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
